\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{xfrac}
\usepackage{csquotes}
\usepackage{caption}
\usepackage{gensymb}
\usepackage{csvsimple} % Read .csv files to tables 
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage[margin=3ex,font=footnotesize,labelfont=bf,labelsep=endash]{caption}
\usepackage{hyperref}
\usepackage[all]{hypcap}
\usepackage[table]{xcolor}
\definecolor{lightgray}{gray}{0.9}
\graphicspath{{./figs/}}
\hypersetup{colorlinks=true,urlcolor=gray,linkcolor=black, citecolor=gray}
\usepackage[english]{babel}
\usepackage[backend=biber, sorting=none]{biblatex}
\addbibresource{bibliography.bib}
\usepackage{amsmath}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\hyphenation{micro-metre}
\hyphenation{Fresnel}
\hyphenation{po-ly-sty-rene}
\hyphenation{Where-as}

% Spara författare och titel
\let\oldAuthor\author
\renewcommand{\author}[1]{\newcommand{\myAuthor}{#1}\oldAuthor{#1}} 
\let\oldTitle\title
\renewcommand{\title}[1]{\newcommand{\myTitle}{#1}\oldTitle{#1}} 

\newcommand{\mail}[1]{\href{mailto:#1}{\nolinkurl{#1}}}
\newcommand\blankpage{\null\thispagestyle{empty}\addtocounter{page}{-1}\newpage}
\newcommand\emptypage{\null\thispagestyle{empty}\newpage}
\newcommand{\figscale}{0.7\textwidth}
\newcommand{\ima}[0]{\overset{\hspace{0.5mm}\text{\scalebox{0.7}{$\circ$}}}{\imath}}

% Hurenkinder und Schusterjungen verhindern
\clubpenalty10000
\widowpenalty10000
\displaywidowpenalty=10000

%%% MATLAB Code
\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % colour values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}
\lstset{language=Matlab,%  %%% for MATLAB Code
    basicstyle=\ttfamily\scriptsize,%
    breaklines=false,%
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},%
    morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},%
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},%
    showstringspaces=false,%without this there will be a symbol in the places where there is a space
    numbers=left,%
    numberstyle={\tiny \color{black}},% size of the numbers
    numbersep=7pt, % this defines how far the numbers are from the text
    emph=[1]{for,end,break,function},emphstyle=[1]\color{red}, %some words to emphasise   
}

% \setcounter{figure}{0}

\title{Off-Axis Digital Holographic Microscopy}
\author{Oliver Irtenkauf\\\mail{oliver.irtenkauf@uni-konstanz.de}} 
\date{November 12, 2018}
\begin{document}
\begin{titlepage}
    \maketitle
    \thispagestyle{fancy}
    \headheight 25pt
    \lhead{\small Umeå University\\Department of Physics}
    \cfoot{\small Master´s Thesis in Physics II, 15 credits\\Supervisor: Magnus Andersson} 
\begin{abstract}
     \noindent Digital holographic microscopy (DHM) is a powerful technique to investigate the shape and geometry of micron-sized objects. For example, due to the interference phenomenon the phase can be reconstructed and from this it is possible to derive optical properties such as the refractive index. This work reports construction of an off-axis DHM setup build using a similar approach as an Michelson interferometer, that is, light is splitted into a probe and reference arm. The angle between these arms was evaluated either by counting fringes, a geometrical relation or using frequency domain information. Also, an algorithm was designed to reconstruct the phase from two different approaches using normalization. Experiments were conducted using polystyrene beads with an diameter of 2.5\,$\micro$m.
\end{abstract}
\end{titlepage}
\newpage
\pagestyle{fancy}
\headheight 25pt 
\rhead{\small \myTitle\\ \today}
%\lhead{\small \myAuthor}
\cfoot{\thepage}
\footskip 45pt

\pagenumbering{Roman}
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}{1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Digital holographic microscopy (DHM) is an imaging technique that is able to extract morphological information, shape and optical thickness from micron-sized objects such as biological cells. Additionally, the possibility to combine DHM with confocal \textsc{Raman} spectroscopy or an optical tweezer setup allows for measurement of biochemical, biophysical and morphological properties of an optical trapped object at the same time.

This report describes the construction of a high precision off-axis DHM setup, that should subsidize an inline DHM version implemented with the current of \textsc{Raman} spectroscopy optical tweezers setup \cite{PMID:16844748}.
%\textcolor{red}{ADD this references: Not perfect but the most relevant for the optical tweezers: Andersson, M., Fällman, E., Uhlin, B. E. & Axner, O. Dynamic force spectroscopy of E. coli P pili. Biophys. J. 91, 2717–25 (2006).} . 
Furthermore, the \texttt{MatLab} \cite{matlab} code to reconstruct the intensity distribution and phase of a microparticle developed in this thesis will be presented.

%\textcolor{red}{Recall that the verb in English should be positioned close to the subject. So when you write think of this, then you also avoid passive language.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}
In the following section the off-axis DHM setup is described. At first, I will present the experimental part, after which I will discuss the numerical reconstruction with \texttt{MatLab}.

\subsection{Setup}
The light path of the off-axis DHM is shown in figure \ref{fig:scheme}. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=.8\textwidth]{setup/setup.png}
    \caption{Scheme of setup. The HeNe laser generates a beam that passes the optical isolator (OI), mirror one and two (M1 \& M2), the beam expander, consisting out of two lenses (L1 \& L2) and reaches the beam splitter (BS1) that splits the beam in the object and reference beam. The object arm consists of two mirrors (M3 \& M4), two objectives (O1 \& O2) and a sample (S) in between. The reference arm includes just two mirrors (M5 \& M6). The two arms are recombined by the second beam splitter (BS2) and guided on a camera (C) which is connected to a computer for data acquisition. }
    \label{fig:scheme}
\end{figure}
A DHM is similar to a \textsc{Mach}-\textsc{Zehnder} setup, however, in the DHM setup optical components that resembles a microscope is added in one of the arms. A laser beam is split between the two arms and allowed to propagate through the microscope. We used a  frequency stabilized HeNe laser (\textit{Spectra Physics}) to image our samples.

At first, the beam is emitted by a frequency stabilized HeNe laser (\textit{Spectra Physics}). It emits linear polarized red light with a wavelength of $\lambda_\text{HeNe}=632.8\,$nm \cite{handbook}. The beam width $d_\text{beam}=1.2\,$mm is determined with a beam profiler \cite{beamprofiler}. The emitted intensity profile $I(r)$ is a \textsc{Gauss} function, where $r$ is the distance to the centre. However, the beam width $d_\text{beam}$ is defined as
\begin{align}
    I(d_\text{beam}/2)\overset{!}{=}e^{-2}I_0\,,
\end{align}
where $I_0$ describes the centre intensity.

At first the beam passes a so called poor mans optical isolator (OI). The first element of the OI is a linear polarizer. Afterwards the light passes the $\lambda/4$-plate and becomes circular polarized. After a second pass-through of the $\lambda/4$-plate plate, the back-reflected light regains linear polarization, perpendicular to the incident light. With this method, the polarization filter blocks harmful back reflections.

In the second stage mirror one and two (M1 \& M2) enable full control of the beam, so that a straight alignment through the following beam expander is given.
%\textcolor{red}{Try to avoid having single sentences. Connect sentences instead so you get flow!}
In the next step the beam is expanded by a \textsc{Kepler} telescope consisting of two positive lenses (L1 \& L2), in order to fill the back-aperture of the objectives (O1 \& O2) correctly.

Furthermore, the back-aperture size $d$ of the objectives is given by
\begin{align}
    d\leq2\cdot\text{NA}\cdot f\,, \label{eq:backaperture}
\end{align}
where $f$ is the focal length and $\text{NA}$ is the numerical aperture. Finally, using equation \ref{eq:backaperture} and the used objectives ($f_\text{O1,2}=4.5\,$mm, $\text{NA}_\text{O1}=0.60$, $\text{NA}_\text{O2}=0.65$ \cite{LCPlanFl}) the back-aperture size is $d_\text{max}=5.4\,$mm.

Also, the magnification $M$ of a \textsc{Kepler} telescope is given by
\begin{align}
    M=-\frac{f_\text{L2}}{f_\text{L1}}\,.
\end{align}
So, the lenses ($f_\text{L1}=100\,$mm \cite{LA1509}, $f_\text{L2}=250\,$mm \cite{LA1461}) are chosen to magnify the beam by $M=2.5$ to $d_\text{expanded beam}=3\,$mm. Neither the back-aperture is over filled, nor the expanded beam is too big for the camera (C) \cite{pointGrey} sensor.

After passing the \textsc{Kepler} telescope, the beam splitter (BS1) \cite{BS013} splits the beam equally in intensity in object and reference beam. Both arms contain two mirrors each (M3, M4 and M5, M6), so that full control of the alignment in each arm is given.

However, the second mirror in the object arm (M4) is mounted on a cage system, as shown in figure \ref{fig:real_setup} in the lower left corner, together with the first objective (O1).
\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\textwidth]{setup/setup_real.png}
    \caption{Photo of the setup, including sample holder (SH) with $x, y, z$ translation freedom and $x,y$ tilt freedom. The setup is surrounded by black card board to ensure laser safety.}
    \label{fig:real_setup}
\end{figure}
In addition this design allows to move mirror M4 and objective 1, while keeping the system aligned. Due to this, the sample holder (SH) can be installed without affecting the alignment.

Moreover, the sample holder (SH) can be moved in $x$, $y$ and $z$ due to micrometre stages. The sample itself can be tilted in $x$ and $y$ direction, as well. This means that the sample is aligned perpendicular to the beam. To ensure this, the first objective can be removed temporarily and the back reflection of the sample can be adjusted back to the laser cavity.

However the second objective (O2) is chosen in a way that is has a slightly smaller numerical aperture NA than the first objective (O1) (compare $\text{NA}_\text{O1}=0.60$ with $\text{NA}_\text{O2}=0.65$). In conclusion, the first objective (O1) focuses the light and generates a point source, whereas the second objective collects the light, producing parallel output. Normally, two equal objectives would definitely be better, where in this case, two different objectives must be used.

To ensure the light leaving the second objective (O2) parallely, the first objective (O1) is mounted on a micrometre stage in the $z$ direction. However, the idea is that the focal points of both objectives are meeting. Therefore, the interferogram, given by object- and reference arm, can be observed. As a result, there should be no concentric circles, caused by either defocus or spherical aberration Only parallel lines, caused by an angle between object- and reference beam, should be observed.

Additionally, in the reference arm, the second mirror (M6) is mounted on a micrometre stage in order to generate an angle between object and reference arm after the second beam splitter (BS2) \cite{BS013} at the camera sensor (C). Further evaluation of the angle is discussed in section \ref{sec:tilt}. In the last step, the data acquisition is done by the CMOS sensor in camera (C) \cite{pointGrey}.

\subsection{Sample Preparation}
To prepare a sample, the following steps are performed. 1\,\textmu l from the cooled bead stock solution is diluted in 1000\,\textmu l ultra-pure water. From this solution, 20-30\,\textmu l are pipetted on a cover slip ($60\times24\,$mm), where the droplet gets covered with a second cover slip ($20\times20\,$mm) to ensure the absence of bead stacks. Then the cover slips are heated in an oven at around 80$\,^\circ$C for several minutes (5-10\,min). Afterwards, the second cover slip can be removed easily from the lower cover slip. Now the sample is prepared and can be attached to the sample holder. Sticking the sample with double-sided adhesive tape to the sample holder is a stable method and achieves easy attachment. Unfortunately, the cover slip might be destroyed when the sample is removed.

\subsection{Reconstruction code} \label{sec:reconstructioncode}
The data from the camera is saved with the \texttt{FlyCapture2} software \cite{flycapture}. Therefore, a fixed shutter time of 0.8-1.6\,ms is chosen, whereas the gain is set to zero. However, the shutter time depends on the saturation and the data should use the full range of the possible 12\,bit \cite{pointGrey}, but on the same hand an oversaturation should be avoided. Otherwise, information would be lost and the image quality would decrease. The full pixel range of $1328\times1048$\,pixel and the format ''Mono 16'' is chosen and the data is saved as \texttt{tiff} \cite{tiff} files. This enables the possibility to save the data unprocessed in 16\,bit, so the saved values have to be normalized by division by 16. Furthermore, the information about the colour is lost, which has no effect, since only monochromatic light is used. 

In the following, image processing is done with \texttt{MatLab} \cite{matlab} and follows the paraxial approximation for \textsc{Fresnel} diffraction by reference \cite{Latychevskaia}. However, the flowchart in figure \ref{fig:flowchart1} shows the most important steps in the program, described below.
\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{setup/flowchart2.png}
    \caption{Flowchart of the program code. The code starts with the normalization, going to the processing, afterwards going to the repropagation and end with the reconstruction. Note that the repropagation is performed for different distances $z$.}
    \label{fig:flowchart1}
\end{figure}

\subsubsection{Normalization} 
At first the recorded hologram $H(X,Y)$, where $X$ and $Y$ are the coordinates in real space at the detector plane, is given by the relation \cite{Verrier:11}
\begin{align}
    H(X,Y)&= \left|O(X,Y)+R(X,Y)\right|^2\\
    &=\left|R(X,Y)\right|^2+\left|O(X,Y)\right|^2+R^*(X,Y)O(X,Y)+R(X,Y)O^*(X,Y)\,, \nonumber
\end{align}
where $O(X,Y)$ is the field of the object beam and $R(X,Y)$ the field of the reference beam. 
In order to handle the relative intensity, the hologram must be normalized.
%\textcolor{red}{You lack the Why in this sentence ... must be normalized, always explain Why. If the reader is not as skilled in DHM as you, they get lost!}.
The Normalization starts with dividing the hologram by a background image $B(X,Y)=|R(X,Y)|^2$ that is recorded without any present object.

Making the assumption that the reference beam is much stronger than the objective beam $\left|R(X,Y)\right|\gg\left|O(X,Y)\right|$, the fraction can be written as
\begin{align}
    \frac{H(X,Y)}{B(X,Y)} &= \frac{\left|O(X,Y)\right|^2}{|R(X,Y)|^2} + \frac{\left|R(X,Y)\right|^2}{|R(X,Y)|^2} + \frac{R^*(X,Y)O(X,Y)}{|R(X,Y)|^2} + \frac{R(X,Y)O^*(X,Y)}{|R(X,Y)|^2}
    \nonumber\\ &\approx 
    \frac{R^*(X,Y)O(X,Y)+R(X,Y)O^*(X,Y)}{|R(X,Y)|^2} + 1\,.
\end{align}
However, subtracting one leads to the normalized hologram $H_0(X,Y)$.

In practice, the normalization can also be performed by a \textsc{Gauss} correction, where the image is fitted by a 2D\,\textsc{Gauss} fit, 
\begin{align}
    f(x,y)=A\cdot\exp\left(-\frac{(x-x_0)^2}{2\sigma_x^2}-\frac{(y-y_0)^2}{2\sigma_y^2}\right)+c\,,
\end{align}
with $A$ the amplitude, $x_0, y_0$ the offsets, $\sigma_x, \sigma_y$ the full width at half maximum, and $c$ a constant offset. Now, an image similar to the background image can be simulated by the fitting parameter. Nevertheless, this fitting is very slow due to its many parameters, so it should only be used when the background is not known.

\subsubsection{Processing and repropagation}
In the next step, an inverse two dimensional \textsc{Fourier} transformation on $H_0(X,Y)$ is performed. However, due to the applied angle between object and reference beam, the auto correlation term $\left|R(X,Y)\right|^2+\left|O(X,Y)\right|^2$ is in the middle of the frequency picture. Unlike the real and twin image, given by $R^*(X,Y)O(X,Y)$ and $R(X,Y)O^*(X,Y)$, are separated from the auto correlation term in $u$ and $v$ direction, where $(u,v)$ are the coordinates in frequency domain. As a conclusion, this separation of twin, real image and auto correlation term in frequency domain is shown in figure \ref{fig:kpic}\subref{fig:frequencyimage} and discussed in reference \cite{Verrier:11}.
%\textcolor{red}{Remove sentence break with the previous paragraph. This sentence has the same topic as the previous! Just break the sentences when you switch the topic of the sentence. }
Now either the twin- or real image is picked, cut out in an elliptical shape and shifted to the centre of the frequency domain. Whereas the ellipticity of the shape depends on the picture dimensions $(n,m)$.

In the next step, the light propagation term $S^*(u,v)$, according to the \textsc{Fresnel} approximation, is calculated by
\begin{align}
    S^*(u,v)=\exp{\left( \ima \pi \frac{\lambda z^3}{f_\text{O2}^2 \cdot d_\text{pixel}^2} \left( \left(\frac{u}{n}\right)^2+\left(\frac{v}{m}\right)^2\right)\right)}\,, \label{eq:propagator}
\end{align}
with $\lambda$ the used wavelength, $f_\text{O2}$ the focal length of the imaging objective (O2) (equal to the distance between source and detector), $d_\text{pixel}$ the size of a pixel and $z$ the distance between detector and object. In order to reconstruct the image, $z$ is varied between $z\approx0$ for a reconstruction at the detector plane and $z=f$ for a reconstruction at the source.

Furthermore, the reconstructed field at different positions in $z$ direction in real space is given by 
\begin{align}
    t(x,y,z)=\text{FT}\left( S^*(u,v,z) \cdot \text{FT}^{-1}\left(H_0(X,Y)\right)'\right)+1\,. \label{eq:field1}
\end{align}
Take into account that the light propagation term $S^*(u,v)$ holds the relation
\begin{align}
    S^*(u,v) =\text{FT}^{-1}\left(s^*(x,y)\right)\,.
\end{align}

\subsubsection{Reconstruction} \label{subsub:reconstruction}
The field that is transmitted by the object, is given by
\begin{align}
    t(x,y):=\exp(-a(x,y))\,\exp(\ima\phi(x,y))\,, \label{eq:field2}
\end{align}
where $a(x,y)$ describes the absorption term and $\phi(x,y)$ the phase. The wrapped phase can be reconstructed by taking the complex angle of the reconstructed field
\begin{align}
    \phi(x,y)=\arg \left( t(x,y)\right)\,. \label{form:phase}
\end{align}
For further reconstruction the phase must be unwrapped.
In addition,the absorption term $a(x,y)$ can be extracted by taking the negative logarithm of the absolute value
\begin{align}
    a(x,y) = -\ln\left| t(x,y) \right|\,. \label{form:absorp}
\end{align}
However, the intensity $I(x,y)$ can be reconstructed, by multiplying with the complex conjugated
\begin{align}
    I(x,y)=\left| t(x,y)\right|^2\,. \label{form:intensity}
\end{align}
Note that the reconstructed coordinates $(x,y)$ in metre are related to the coordinates $(n,m)$ in pixels at the detector plane, given by
\begin{align}
    (x,y)=(n,m)\,d_\text{pixel}\cdot \frac{z}{f_\text{O2}}\,,
\end{align}
whereas the coordinates $(n,m)$ are connected to real space coordinates $(X,Y)$ in metres, by
\begin{align}
    (n,m)=\left. (X,Y) \middle/ d_\text{pixel} \right.\,.
\end{align}
For further technical details, see appendix \ref{appendix:code}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
The following section presents the reconstruction results of intensity and phase, as described in section \ref{sec:reconstructioncode}. To perform this, the converting factor to estimate the size of one pixel in metres is required. Also, the angle between object- and reference arm is evaluated by different methods, before the different reconstruction steps are shown. Finally, the reconstructed intensity, absorption and phase from the hologram is presented.

\subsection{Converting factor}
In order to evaluate the converting factor which connects the pixels on the image, with the real space a micrometre ruler is used. Firstly, the distance between each line on the ruler is known to be $10\,$\textmu m. Now, by acquiring an image of the micrometre ruler, the converting factor can be calculated by dividing the line distance in metre by the distance in pixels. However, figure \ref{fig:calibration} shows the image of the micrometre ruler and the intensity plot for $x=600$\,pixel. The distance between the peaks is estimated with the help of a peak finder and is found to be $167(5)\,$pixels. This means that the converting factor is $60(2)\,\frac{\text{nm}}{\text{pixel}}$. By relating the pixel size with the converting factor, the whole systems magnification is found to be $M_\text{exp}=60.5(21)$. However, comparing this with the magnification of the second objective $M_\text{O2}=40$ leads to an inconsistency in magnification and needs to be verified later on.
\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{Calibration/calibration.eps}
    \caption{(a) Image of a micrometre ruler to estimate the converting factor.\\
    (b) Intensity $I(y)$ profile along the vertical line at $x=600\,$pixel. Grey lines indicate the positions local minima, caused by the micrometre ruler.}
    \label{fig:calibration}
\end{figure}

\subsection{Angle between object and reference arm} \label{sec:tilt}
In order to separate twin or real image from the auto correlation term of the hologram in the \textsc{Fourier} domain, an angle between the object and reference arm has to be applied (see section \ref{sec:reconstructioncode}).
Three different methods to determine the angle between the object and reference arm are used. The following subsection calculates the angle for a slightly tilted and slightly out of focus system by using a polystyrene sphere with a diameter of $9.5\,$\textmu m.
\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{evatilt/raw_image.eps}
    \caption{Unprocessed image of a 9.5µm polystyrene (PS) bead. The red circle indicates the assumed illumination field, whereas the blue circle indicates the position and size of the PS bead. The stripes, also, known as fringes, are caused by interference between object and reference arm.}
    \label{fig:raw_image}
\end{figure}

The first method to estimate the tilt between object and reference arm is counting the number of fringes (Figure \ref{fig:raw_image}) and measure the distance between them within the illumination field within the image (via \texttt{GNU Image Manipulation Program} (\texttt{GIMP}) \cite{GIMP}). With this, the average fringe distance $N_\text{fringe}$ in pixels can be determined. Now, by knowing the illumination wavelength $\lambda_\text{HeNe}$ and the pixel size $d_\text{pixel}$, the angle $\phi_\text{fringe}$ between object and reference arm can be calculated with the formula
\begin{align}
    \phi_\text{fringe}=\sin^{-1}\left(\frac{\lambda_\text{HeNe}}{N_\text{fringe}\cdot d_\text{pixel}}\right)\,.
\end{align}
However the derivation is similar to the \textsc{Young}'s double-slit experiment.
Where- as the distance between two subsequent fringes is $N_\text{fringe}=14.8(2)\,$pixel, which is calculated by taking the mean value and standard deviation for multiple measuring points. With the wavelength $\lambda_\text{HeNe}=632.8\,$nm \cite{handbook} and the pixel size $d_\text{pixel}=3.63\,$\textmu m of the camera \cite{pointGrey}, the calculated angle is $\phi_\text{fringe}=0.675(9)\,^\circ$. Finally, the uncertainty is determined with the \textsc{Gaussian} error propagation.

The second method to determine the angle between measurement and reference arm is based on geometry and takes advantage of the special \textsc{Mach}-\textsc{Zehnder} interferometer design. However, at the beam splitter cube where the measurement and reference arms merge (figure \ref{fig:scheme}, BS2), two images of the particle under investigation are formed. One of these images is used for data acquisition by a camera, the other one is unused on a second screen, as seen in figure \ref{fig:geom}.
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{setup/geom.eps}
    \caption{Geometrical method to measure the angle $\alpha_\text{geom}$ between object and reference beam (marked with grey areas). Note that the coordinate system is rotated by $90\,^\circ$ in comparison to figure \ref{fig:scheme}.}
    \label{fig:geom}
\end{figure}
Since the object and reference arm meet at the camera position, they will separate again after this point is passed. By measuring the beam separation ($d_\text{spots}$) at a known distance to the image point ($b_\text{screen}-a_\text{camera}$), the angle can be determined by equation
\begin{align}
    \alpha_\text{geom} = \tan^{-1} \left( \frac{b_\text{screen}-a_\text{camera}}{d_\text{spots}}\right)\,.
\end{align}
However, for the measured values $a_\text{camera}=0.08(1)$\,m, $b_\text{screen}=6.33(5)$\,m and $d_\text{spots}=0.075(1)$\,m the determined angle is $\alpha_\text{geom}=0.69(2)\,^\circ$, where the uncertainty calculation is done with the \textsc{Gaussian} error propagation.

The third method is based on the properties of the frequency domain and the separation of the twin- and real image from the auto correlation term due to the applied angle. So, if the twin image is not centred, the angle can be found again in the reconstructed phase, as shown in figure \ref{fig:phasenplane}.
\begin{figure}[h!]
    \centering
    \includegraphics[width=.8\textwidth]{evatilt/phasenplane.eps}
    \caption{Reconstructed phase at the detector, where the frequency image is not centred. Blue circles indicate position and size of the polystyrene bead. The fitted planes angle to the detector is $\theta_\text{plane}=0.677\,^\circ$.}
    \label{fig:phasenplane}
\end{figure}
Consequently, the reconstructed phase can be fitted with a plane fit, using the least squares algorithm \cite{plane_fit}. Therefore, the normal vector and its angle to the $z$-axis can be calculated. Here, the wavelength and the pixel size must be considered, as well, to calculate the angle correctly. Finally, the estimated value for the angle is $\theta_\text{plane}=0.677\,^\circ$. In short, an error calculation is quite difficult to perform and due to its way of estimating the angle, the method itself is definitely the most contributing part. In addition, errors in the phase unwrapping or the fits uncertainty is difficult to quantify. 

However, the three presented methods of evaluating the angle between the object and the reference beam give reasonable angles. In conclusion, all the angles
\begin{align*}
    \phi_\text{fringe}&=0.675(9)\,^\circ\,,\\
    \alpha_\text{geom}&=0.69(2)\,^\circ\,,\\
    \theta_\text{plane}&=0.677\,^\circ\,,
\end{align*}
are in the uncertainty range of each other. Thus, all methods are deemed valid to determine the angle. In the following, a larger angle for further experiments is chosen to increase the spatial separation between the twin image, auto correlation and real image.

However, the maximum angle to actually resolve fringes is given by \cite{Verrier:11}
\begin{align}
    \phi_\text{fringe}\leq \arcsin\left( \frac{\lambda_\text{HeNe}}{2\,d_\text{pixel}}\right)\,. \label{eq:maxangle}
\end{align}
Now, by considering the wavelength used and the camera pixel size, this value is calculated to be smaller than $5\,^\circ$, where otherwise information is lost. Consequently, to achieve maximal separation between the auto correlation term and the real and twin image in the frequency domain an angle just slightly under this maximum angle is used.

However, by increasing the angle between the reference and measurement arm, the fringe distance method to determine this angle becomes uncertain. The fringe distance at the maximum angle (e.g. for example $N_\text{fringe}=2(1)\,$pixel) can not be estimated better, so the relative error significantly increases. In contrast, the geometrical method delivers even better results with a smaller relative uncertainty for greater angles, due to a long distance between beam splitter and screen. So, the distance between the two spots increases fast and its uncertainty, given by the spot diameter, is constant, so the relative uncertainty gets much smaller. Also, the angles in $x$ and $y$ direction are quite easy to calculate. Since a proper uncertainty estimation for the plane fitting method is challenging, the geometrical method is used hereafter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reconstruction} \label{results:reconstruction}
The following section shows the results of reconstruction of intensity, absorption and phase. However, the investigated particle is a $2.5\,$\textmu m diameter polystyrene bead with an index of refraction of $n=1.591$ \cite{bead24, bead26}. Furthermore, the tilt angle between the object and reference arm is determined geometrically, so the effective angle and its components in the $x$ and $y$ direction are
\begin{align}
    \alpha_\text{geom}&=2.54(3)\,^\circ\,,\\
    \alpha_{\text{geom,\,}x}&=2.21(2)\,^\circ\,,\\
    \alpha_{\text{geom,\,}y}&=1.24(2)\,^\circ\,.
\end{align}
%Note that a histogram \textcolor{red}{This is unclear, do you refer to Figure 14? Also fix the figure positions, now figure 14 is way done the document. Set the layout of the document so figures are close to the text.} , see figure \ref{fig:histogram}, assure a good saturation, without over saturation during image acquisition. 
Note that an intensity histogram, as shown in figure \ref{fig:histogram}, assures a good saturation without oversaturation during image acquisition.
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{Reconstruction/Background.eps/histogram.eps}
    \caption{Logarithmic distribution of intensity $D(I)$.  The highest recorded intensity is 3675,  whereas the maximum value of the 12\,bit data is 4096, so the saturation during image acquisition is chosen right.}
    \label{fig:histogram}
\end{figure}
Additionally, the sample is approximately 20\,\textmu m out of focus.
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{Reconstruction/Background.eps/12-bit_Image.eps}
    \caption{Unprocessed image. Red circle indicates field of illumination, blue circle indicates polystyrene bead.}
    \label{fig:12bit}
\end{figure}
Also, the size of the polystyrene bead in pixels is estimated by the theoretical diameter and the converting factor. In addition, to initialize the reconstruction of intensity, absorption and phase, a "field of illumination" is defined in the image. It is approximated by eye and limits the evaluated data, as well as to save computation power. Additionally, educated guesses of the centre and half width of the fitted 2D\,\textsc{Gauss} function can be derived.

\subsubsection{Normalization}
In the next step, the normalization of the hologram is done by using two different approaches. However, the hologram is either normalized by division with a background image (figure \ref{fig:normalized}\subref{fig:norm_background}) or by fitting the hologram with a 2D\,\textsc{Gauss} fit, simulating the background (figure \ref{fig:gauss}) and dividing the hologram by this background (figure \ref{fig:normalized}\subref{fig:norm_gauss}).
\begin{figure}
    \centering
    \subfigure[Background]{
    \includegraphics[height=40mm]{Reconstruction/Background.eps/normalizedImage.eps}
    \label{fig:norm_background}}
    \subfigure[2D\,\textsc{Gauss}]{
    \includegraphics[height=40mm]{Reconstruction/Gauss.eps/normalizedImage.eps}
    \label{fig:norm_gauss}}
    \caption{Normalized image $H_0(X,Y)$. Normalization in \subref{fig:norm_background} by background, in \subref{fig:norm_gauss} by 2D\,\textsc{Gauss} Fit. Red circle indicates Field of Illumination, blue circle indicates polystyrene bead.}
    \label{fig:normalized}
\end{figure}
Consequently, in both figures the illumination field is more homogeneous, also, features from the imaging and diffraction are highlighted by a higher amplitude. 

\subsubsection{Frequency domain}
Afterwards, the normalized image is 2D\,\textsc{Fourier} transformed, as shown in figure \ref{fig:kpic}\subref{fig:frequencyimage}.
\begin{figure}[!ht]
    \centering
    \subfigure[Spatial frequency image $I(u,v)$ in terms of $\log\left|\text{FT}^{-1} \left( H_0(X,Y)\right)\right|$.]{
    \includegraphics[width=.8\textwidth]{Reconstruction/Background.eps/SpatialFrequencyImage.eps}
    \label{fig:frequencyimage}}
    \subfigure[Cut and shifted spatial frequency image $I'(u,v)$ in terms of $\log\left|\text{FT}^{-1} \left( H_0(X,Y)\right)'\right|$.]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/shiftedFFT.eps}
    \label{fig:shift}}
    \subfigure[Light propagator $s^*(u,v)$ in terms of $\log\left(\text{Re}\left(\text{FT}^{-1}\left(s^*\left(x,y,z=9000\,\text{\textmu m}\right)\right)\right)\right)$.]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/propagator_z9000.eps}
    \label{fig:prop}}
    \caption{Spatial frequency image. Light green circle indicates the separated twin image.}
    \label{fig:kpic}
\end{figure}
However, the light green circle (continuous line) corresponds to the position and size of the twin image, whereas the dark green circle (dash-dotted line) corresponds to the real image. In fact, there is no difference between them, since the \textsc{Fourier} transformation is symmetric. The blue circle (dashed line) indicates the auto correlation term. Beside the real and twin image and the auto correlation term, several more objects can be observed in the frequency domain, marked by grey circles (dotted line). They originate from high order back reflections and have a different angle or offset compared to the twin or real images. Since in the in-line DHM, there is no applied angle between object and reference beam and the twin and real image are overlapping with the auto correlation term. However, applying an angle leads to a separation between these three images in the frequency domain. Take into account, that an angle in $x$ direction shifts the twin or real image just in $x$ direction in the spatial frequency image. Note that a complete separation of twin or real image and higher order back reflection is only successful, if a significant angle in $x$ and $y$ direction is applied. Nevertheless, from equation \ref{eq:maxangle} the angle for maximum separation is known. To separate the twin and real image from the auto correlation term to a sufficient extent but still resolve the full twin and real image, an angle between the maximum angle and zero must be set. However, in this case the set angle is approximately the half of the maximum angle.
%\textcolor{red}{Unclear section: Besides the real and twin image and the auto correlation term, several more objects can be observed in the frequency domain (figure \ref{fig:kpic}\subref{fig:frequencyimage}). They originate from high order back reflections. They have a different angle or offset compared to twin or real image.}

Furthermore the size of the twin or real image depends on the distance between the source and object ($z$, in direction of light propagation). Also, the radius of the auto correlation term is twice the radius of the twin- or real image \cite{Verrier:11}. Due to the symmetry of the \textsc{Fourier} transformation, there is no difference in the information gained from the twin- or real image. So, in practice, there is no difference in which one of the images is chosen for reconstruction.

Besides, figure \ref{fig:kpic}\subref{fig:prop} shows the propagator $\text{Re}\left(S^*(u,v)\right)$ (equation \ref{eq:propagator}), for the distance $z=9000$\,\textmu m. However, the shown pattern is the \textsc{Fresnel} zone plate. 

Furthermore, the elliptical shape of the twin-, real image, auto correlation term but also the propagator, depends on the picture dimension $(n,m)$. Thus, the smaller semi-axis $b$ can be related to the larger semi-axis $a$, as
\begin{align}
    b=\frac{n}{m}\,a\,. \label{form:ellipse}
\end{align}
Therefore, if the dimensions $n=m$ are equal and the picture is a square the shape will be circular.

\subsubsection{Repropagation of the light}
Figure \ref{fig:flowchart} displays the repropagation of intensity and phase for different values of $z$. However, the repropagation along the $z$ axis is done for a fixed $y$ coordinate, corresponding to the particle centre $c_y$. As one can see in figure \ref{fig:flowchart}\subref{fig:flow_intensity_mesh} and \ref{fig:flowchart}\subref{fig:flow_phase_mesh} the plots for the surface of intensity $I(x,y=c_y,z)$ and phase $\phi(x,y=c_y,z)$ are shown, respectively. This is calculated for the real space coordinates, in contrast to figures \ref{fig:flowchart}\subref{fig:flow_intensity_image} and \ref{fig:flowchart}\subref{fig:flow_phase_image}, which show the detector coordinates in pixels $I(X,Y=C_Y)$ for different lateral steps $i$ in the $z$ direction. Therefore, the real space shrinks from the detector to a point source, whereas the amount of information is constant. In short, this is consistent with the paraxial \textsc{Fresnel} approximation.
\begin{figure}[ht]
    \centering
    \subfigure[Intensity surface plot $I(x,c_y,z)$]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/flowchart-mesh-intensity.eps}
    \label{fig:flow_intensity_mesh}}
    \subfigure[Intensity image $I(X,Y=C_Y,i)$]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/flowchart-image-intensity.eps}
    \label{fig:flow_intensity_image}}
    \subfigure[Phase surface plot $\phi(x,c_y,z)$]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/flowchart-mesh-phase.eps}
    \label{fig:flow_phase_mesh}}
    \subfigure[Phase image $\phi(X,C_Y,i)$]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/flowchart-image-phase.eps}
    \label{fig:flow_phase_image}}
    \caption{Flow chart for repropagated light at $C_Y=506\,$pixel.}
    \label{fig:flowchart}
\end{figure}
Subsequently, a greater source to screen distance (focal length of the second objective $f_\text{O2}$) and a bigger camera sensor results in a higher spatial resolution, as long as the numerical aperture is high enough.

However, the next step is to repropagate the field $t(x,y,z)$ (eq.\,\,\ref{eq:field1}) for the right source-to-object distance. The approximated out of focus distance of 20\,\textmu m is the most interesting part, so the figures \ref{fig:reconstructed} are plotted for the distance $c_z=20$\,\textmu m.

\subsubsection{Intensity, absorption and phase}
Figure \ref{fig:reconstructed} shows the results from the reconstruction. On the left side, \ref{fig:reconstructed}\subref{fig:reconstructed_intensity_background}\subref{fig:reconstructed_absorption_background}\subref{fig:reconstructed_phase_background}
are the results using image normalization by dividing with the background image, whereas on the right side in figures \ref{fig:reconstructed}\subref{fig:reconstructed_intensity_gauss}\subref{fig:reconstructed_absorption_gauss}\subref{fig:reconstructed_phase_gauss} the image normalization is done with the 2D\,\textsc{Gauss} fit.
However, the first row \ref{fig:reconstructed}\subref{fig:reconstructed_intensity_background}\subref{fig:reconstructed_intensity_gauss}, shows the reconstructed intensity $I(x,y)$, the second row \ref{fig:reconstructed}\subref{fig:reconstructed_absorption_background}\subref{fig:reconstructed_phase_background}, shows the reconstructed absorption $a(x,y)$ and the third row \ref{fig:reconstructed}\subref{fig:reconstructed_phase_background}\subref{fig:reconstructed_phase_gauss}, shows the reconstructed and unwrapped phase $\phi(x,y)$, according to section \ref{subsub:reconstruction}.
\begin{figure}
    \centering
    \subfigure[Intensity $I(x,y)$ - Background]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/reconstructed_intensity_z0020.eps}
    \label{fig:reconstructed_intensity_background}}
    \subfigure[Intensity $I(x,y)$ - 2D\,\textsc{Gauss}]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Gauss.eps/reconstructed_intensity_z0020.eps}
    \label{fig:reconstructed_intensity_gauss}}
    \subfigure[Absorption $a(x,y)$ - Background]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/reconstructed_absorption_z0020.eps}
    \label{fig:reconstructed_absorption_background}}
    \subfigure[Absorption $a(x,y)$ - 2D\,\textsc{Gauss}]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Gauss.eps/reconstructed_absorption_z0020.eps}
    \label{fig:reconstructed_absorption_gauss}}
    \subfigure[Unwrapped phase $\phi(x,y)$ - Background]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Background.eps/reconstructed_phase_z0020.eps}
    \label{fig:reconstructed_phase_background}}
    \subfigure[Unwrapped phase $\phi(x,y)$ - 2D\,\textsc{Gauss}]{
    \includegraphics[width=.47\textwidth]{Reconstruction/Gauss.eps/reconstructed_phase_z0020.eps}
    \label{fig:reconstructed_phase_gauss}}
    \caption{Reconstructed intensity $I(x,y)$, absorption $a(x,y)$ and unwrapped phase $\phi(x,y)$ for $c_z=20\,$\textmu m. Normalization was performed by division by the background image on the left side and by 2D\,\textsc{Gauss} fit on the right side.}
    \label{fig:reconstructed}
\end{figure}

In the middle of the particle, a peak in the reconstructed intensity $I(x,y,c_z)$ can be observed. Furthermore, the diameter is similar in size compared to the polystyrene bead. However, the peak and shadow might also correspond to the scattering behaviour of the particle, where the maximum is along the optical axis and gets lower for greater angles, until it gets bigger again. Take into account, that the relation $d\ll\lambda$ does not hold true and therefore the \textsc{Rayleigh} theory cannot be applied. However, figure \ref{fig:wikiMie} actually shows the \textsc{Lorenz}-\textsc{Mie} scattering of a 2\,\textmu m sphere at 633\,nm. Therefore, it is obvious that most intensity is scattered in forward direction. Due to its nearly similar condition, this might explain the central peak and surrounding shadow most correctly. %\textcolor{red}{best ... not right word, make clear}.
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{3D_Miestreuung_an_2um_Kugel.jpg}
    \caption{3D\,projection of \textsc{Lorenz}-\textsc{Mie} scattering of red light (633\,nm) on a spherical particle with a 2\,\textmu m diameter. The particle is in the centre at $x=y=z=0$, the light hits the particle from the negative $y$ direction. The expansion of the surface is equal to the logarithm of scattering intensity in this direction. The intensity of the scattered light depends on the scattering. The colour corresponds to the position in $z$ direction. \cite{wikiMie}}
    \label{fig:wikiMie}
\end{figure}

The second row of figure \ref{fig:reconstructed}\subref{fig:reconstructed_absorption_background}\subref{fig:reconstructed_phase_background} shows the reconstructed absorption\\$a(x,y,c_z)$. Also, the absorption depends on the magnitude of the reconstructed field $|t(x,y,c_z)|$, such as the intensity. Due to this, the absorption shows similar behaviour to the intensity, except for the change in sign and scale. Also, in the centre of the particle, the absorption has a sharp peak. One can observe this in the inverse of the intensity, as well as a sharp dip within the central peak, but is not observable in the figures \ref{fig:reconstructed}\subref{fig:reconstructed_intensity_background}\subref{fig:reconstructed_intensity_gauss} at the current angle of view. Consequently, this might be also due to \textsc{Lorenz}-\textsc{Mie} scattering. 

In the third row of figure \ref{fig:reconstructed}\subref{fig:reconstructed_phase_background}\subref{fig:reconstructed_phase_gauss}, the reconstructed and unwrapped phase $\phi(x,y,c_z)$ is shown.
In general, the phase depends on which path the light travels. The index of refraction is much higher in presence of the particle and due to this the phase travels slower than in the surrounding medium. This means that the phase should be retarded compared to the phase that did not travel through the bead.
%\textcolor{red}{UNCLEAR In presence of the particle, the phase should be retarded compared, to the phase, that did not travel the bead.}
However, this shift in phase in presence of the particle can be clearly observed. Subsequently, assuming a maximum path length $L$ equal to the bead diameter and by knowing the refractive index $n$ of the particle in air, the maximum shift in phase $\Delta\phi$ can be calculated by 
\begin{align}
    n=1+\frac{\Delta\phi}{L}\,\frac{\lambda}{2\,\pi}\,,
\end{align}
whereas $\lambda$ is the used wavelength. This means that, the theoretical phase shift is $14.67\,$rad. Assuming the phase shift in figure \ref{fig:reconstructed}\subref{fig:reconstructed_phase_background} by the maximum value yield 0.3\,rad. In summary, the measured phase differs by a lot from the theoretical value.

Also, a small unexpected peak within the dip at the particle's position can be observed. this leads to the conclusion that the results were distorted by problems with the phase unwrapping. Different functions were tested, but none yielded good results.

Apart from this, there might be a \textsc{Gouy} phase shift by $\pi$. It occurs when a \textsc{Gaussian} beam gets focused.
%\textcolor{red}{ADD A TRANSITION TO THE NEW SENTENCE HERE TO GET FLOW}
The focal length $f$ for a spherical ball-shaped lens is given by \cite{balllens}
\begin{align}
    f=\frac{R}{2}\frac{n}{n-1}\,,
\end{align}
where $R$ is the sphere's radius and $n$ its refractive index. The polystyrene bead's focal length is given by $f_\text{bead}=1.7(1)\,$\textmu m. The propagated path length, given by the focal length of the second objective $f_\text{O2}=4.5$\,mm is much greater than the beads focal length $f_\text{O2}\gg f_\text{bead}$, which means that the light is focused by the polystyrene bead before it hits the detector. Therefore, the phase unwrapping might be disturbed by this additional shift in phase by $\pi$, as well. 

In addition, the \textsc{Lorenz}-\textsc{Mie} scattering depends on the incident polarization of the light, which in this case is circularly polarized due to the optical isolator. Since the polarization is directly connected to the phase, this influences the reconstructed phase, as well, but it is hard to tell in which quality and quantity this happens.

Finally, the results of the two different normalization methods are compared. First of all, the reconstruction of intensity and absorption behave similar, whereas the phase behaves slightly different. However, the qualitative behaviour is the same, i.e. the bead shadow is a local minimum with a peak in the centre. However, in the 2D\,\textsc{Gauss} fit normalization the peak in the middle is much smaller and the phase average is smaller as well.

\section{Discussion}
%\textcolor{red}{When you write, try to state the problem, and give the solution, that will make it easier for the reader. For example: High order back reflections, as seen in figure \ref{fig:kpic}\subref{fig:frequencyimage}, are problematic since the twin- and real image of the direct incident beam vanishes. This can, however, be solved by slightly tilting the camera, with respect to the optical axis.}
%\textcolor{green}{To improve the setup, the camera might be slightly tilted, with respect to the optical axis. So, maybe the high order back reflections, seen in figure \ref{fig:kpic}\subref{fig:frequencyimage}, vanishes and the twin- and real image of the direct incident beam can be extracted more easily.}
High order back reflections, as seen in figure \ref{fig:kpic}\subref{fig:frequencyimage}, are problematic since the twin- and real image of the direct incident beam vanishes. This can, however, be solved by slightly tilting the camera with respect to the optical axis.
In addition, there would be more space for higher frequencies without overlapping with other terms. To sample more information of the higher frequencies, we suggest to use a camera with higher resolution, i.e. higher in number of pixels. Furthermore, image quality can be improved by matching the field of illumination to the camera chip size. Currently, as can be seen in figure \ref{fig:12bit}, the field of illumination fills the sensor height to just about 50\,\% and the width even less. Thus, if the beam gets expanded twice, the resolution doubles, as well and so does the diameter of twin- and real image.

In order to achieve a less strong image of the bead and a more significant diffraction pattern, like one can see in figure \ref{fig:12bit}, the measurement itself might be improved by moving the sample more out of focus. This means that the imaging effect will decrease significantly, whereas the diffraction pattern should be more visible in comparison. This may be helped also by decreasing the structure size down to the used wavelength or below. In consequence, the diffraction pattern might dominate the hologram.

However, the normalization, like you can see in figure \ref{fig:normalized}, by the 2D\,\textsc{Gauss} profile gives quite acceptable qualitative results. Since the difference in phase is not understood right now, it is hard to tell its validity. Due to its huge computational effort, the 2D\,\textsc{Gauss} fit can only be recommended for reconstruction, if there is no background image taken. Also, this approximation bases on the assumption that the reference beam can be described by a 2D\,\textsc{Gauss} profile.

Finally, the validity of the theory, used for reconstruction of intensity, absorption and phase, itself must be questioned as well. In short, the used model, the paraxial \textsc{Fresnel} approximation \cite{Latychevskaia}, requires a point-like light-source. However, the laser beam still has a certain diameter in the focal point of the first objective (O1). In Fact, it is even larger than the observed particles diameter. In the end, that might be the reason why the bead gets imaged and does not evolve a stronger diffraction pattern. Some further investigation about the validity, by assuming a point source, must be done.
%\textcolor{red}{UNCELAR The \textsc{Fresnel} model in reference \cite{Latychevskaia} is used, due to the two objectives, the source can be seen as a point source. But in practice, the laser beam still has a certain diameter, even a quite large diameter in comparison to the particle. In the end, that might be the reason, why the bead gets imaged and do not evolve a stronger diffraction pattern. Some further investigation about the validity, by assuming a point source, must be done.}
In addition, this might be resolved by probing a significantly smaller particle, that is below the \textsc{Abbe} limit, so an image can not be resolved and a stronger diffraction pattern can be seen. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\setcounter{page}{1}
\pagenumbering{roman}
\printbibliography[heading=bibintoc]
\newpage
\appendix
\section{Appendix} 
\subsection{Additional figures} \label{appendix:figure}
Figure \ref{fig:gauss} corresponds to the reconstruction in subsection \ref{results:reconstruction}. 
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{Reconstruction/Gauss.eps/gauss.eps}
    \caption{Surface plot of fitted 2D\,\textsc{Gauss}.}
    \label{fig:gauss}
\end{figure}
\subsection{Programm code} \label{appendix:code}
The results of reconstruction, presented in subsection \ref{results:reconstruction}, are made with the following \texttt{MatLab} code.
\lstinputlisting{Reconstruction/reconstruction.m}
The following function cuts out an ordinary circle, with centre $(x,y)$ and radius $r$, given by \texttt{coord}, out of an array, given by \texttt{picture}, and fills the rest with a certain value, given by \texttt{value}.
\lstinputlisting{Reconstruction/function/cutcircle.m}
Same as before but can handle and give back complex values.
\lstinputlisting{Reconstruction/function/cutcomplexcircle.m}
In principle still the same but cut out ellipse and can handle complex value. The semi-axis are related by equation \ref{form:ellipse}.
\lstinputlisting{Reconstruction/function/cutcomplexellipse.m}
Following function fits data of array \texttt{picture} with 2D\,\textsc{Gauss} fit, where start point for the parameter are reconstructed from \texttt{illumination} and give back array \texttt{gauss}, filled with values, calculated by the parameter of the fit, without offset. also, it gives back offset \texttt{const} and fit parameter \texttt{parameter}.
\lstinputlisting{Reconstruction/function/gauss2d_fit.m}
In the following function, a plane fit is performed on array \texttt{picture}, where \texttt{plane} gives back array with fitted plane. With the real space calibration in $x$ and $y$ direction \texttt{Psize} and in $z$ direction \texttt{lambda}, the angle of the plane \texttt{theta} can be calculated.
% make function more functional, calculate shape, substitude cutted
\lstinputlisting{Reconstruction/function/plane_n_angle.m}
Now, the functions, that generate the figures, are coming up. Basically, they take an array, that should be imaged \texttt{picture}, different coordinates \texttt{illumination}, \texttt{particle} or \texttt{twinimage}. These circles are either plotted into the figure or is relevant for the limits of the axis. \texttt{ID} indicates the number of the figure. \texttt{title\_name} sets the title of the figure, what is very useful for working at the code.
\lstinputlisting{Reconstruction/function/show_rawimage.m}
\lstinputlisting{Reconstruction/function/show_hist.m}
\lstinputlisting{Reconstruction/function/show_gauss.m}
\lstinputlisting{Reconstruction/function/show_FFTimage.m}
\lstinputlisting{Reconstruction/function/show_frequencyimage.m}
The next function generates more unique figures in the way, that it has two arrays \texttt{intensityflow} and \texttt{phaseflow} that contains the data and two arrays \texttt{objectplane} and \texttt{yy} which are responsible for the right real space calibration of the \texttt{mesh} figures. In addition, it generates four figures.
\lstinputlisting{Reconstruction/function/show_flowchart.m}
Now the next three functions are responsible for the final reconstruction figures. Like before they also, take the real space arrays \texttt{meshx} and \texttt{meshy}.
\lstinputlisting{Reconstruction/function/show_intensity.m}
\lstinputlisting{Reconstruction/function/show_absorption.m}
\lstinputlisting{Reconstruction/function/show_phase.m}
Finally, the figures must be saved. Name, folder and the figure that should be saved are given by \texttt{name}, \texttt{path} and \texttt{ID}.
\lstinputlisting{Reconstruction/function/save_image.m}

The phase unwrapping function \texttt{phase\_unwrap} is provided by reference \cite{phase_unwrapp}, the plane fitting function \texttt{plane\_fit} is provided by reference \cite{plane_fit} and slightly changed function \texttt{plotCircle3D} is provided by reference \cite{plotCircle3D}. 
\lstinputlisting{Reconstruction/function/plotCircle3D.m}
\end{document}